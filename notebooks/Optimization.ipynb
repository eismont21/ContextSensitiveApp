{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Optimization\n",
    "## a) Based on Model Selection exercise, we choose Decision Tree model to optimize with Bayesian Optimization\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics\n",
    "import sklearn.model_selection\n",
    "from pathlib import Path\n",
    "SEED = 42 # for reproducibility"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Retrieve Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "df = pd.read_csv(Path(\"../data/clean_data.csv\"))\n",
    "X = df.loc[:, df.columns.drop(['label'])]\n",
    "y = df.loc[:, 'label']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = \\\n",
    "    sklearn.model_selection.train_test_split(X, y, stratify=y, test_size=0.2, random_state=SEED)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Parameters to optimize"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "params = {\n",
    "    #'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : np.arange(1, 100),\n",
    "    #'min_samples_split': np.arange(2, 100)\n",
    "    #'criterion' :['gini', 'entropy'],\n",
    "    #'max_leaf_nodes': np.arange(2, 100),\n",
    "    #'min_samples_split': [2, 3, 4],\n",
    "    #'ccp_alpha': [0.1, .01, .001],\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Bayesian Optimization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9870967741935484\n",
      "OrderedDict([('max_depth', 71)])\n",
      "DecisionTreeClassifier(max_depth=71, random_state=42)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "# define evaluation\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=SEED)\n",
    "# define the search\n",
    "search = BayesSearchCV(estimator=DecisionTreeClassifier(random_state=SEED), search_spaces=params, n_jobs=-1, cv=cv)\n",
    "# perform the search\n",
    "search.fit(X_train, y_train)\n",
    "# report the best result\n",
    "print(search.best_score_)\n",
    "print(search.best_params_)\n",
    "print(search.best_estimator_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluation on test dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score 0.974025974025974\n"
     ]
    }
   ],
   "source": [
    "# evaluate on test\n",
    "predictions = search.best_estimator_.predict(X_test)\n",
    "print(\"Accuracy score\", sklearn.metrics.accuracy_score(y_test, predictions))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score 0.974025974025974\n"
     ]
    },
    {
     "data": {
      "text/plain": "DecisionTreeClassifier(max_depth=100, random_state=42)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check by training from scratch using best_params_\n",
    "clf = DecisionTreeClassifier(max_depth=100, random_state=42)\n",
    "#DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features='auto', random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "print(\"Accuracy score\", sklearn.metrics.accuracy_score(y_test, predictions))\n",
    "clf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## b) Compare against automl using a fitting crossvalidation on resampling stategy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auto-sklearn results:\n",
      "  Dataset name: 60770c08-1ce3-11ed-b9fe-c9f1e3b42d6a\n",
      "  Metric: accuracy\n",
      "  Best validation score: 0.983713\n",
      "  Number of target algorithm runs: 12\n",
      "  Number of successful target algorithm runs: 11\n",
      "  Number of crashed target algorithm runs: 0\n",
      "  Number of target algorithms that exceeded the time limit: 1\n",
      "  Number of target algorithms that exceeded the memory limit: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import autosklearn.classification\n",
    "automl = autosklearn.classification.AutoSklearnClassifier(\n",
    "    time_left_for_this_task=120,\n",
    "    per_run_time_limit=30,\n",
    "    disable_evaluator_output=False,\n",
    "    resampling_strategy='cv',\n",
    "    resampling_strategy_arguments={'folds': 10},\n",
    ")\n",
    "automl.fit(X_train, y_train)\n",
    "print(automl.sprint_statistics())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score CV 0.961038961038961\n"
     ]
    }
   ],
   "source": [
    "predictions = automl.predict(X_test)\n",
    "print(\"Accuracy score CV\", sklearn.metrics.accuracy_score(y_test, predictions))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Perform refit. During fit(), models are fit on individual cross-validation folds. To use all available data, we call refit() which trains all models in the final ensemble on the whole dataset."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score CV 0.961038961038961\n"
     ]
    }
   ],
   "source": [
    "automl.refit(X_train.copy(), y_train.copy())\n",
    "predictions = automl.predict(X_test)\n",
    "print(\"Accuracy score CV\", sklearn.metrics.accuracy_score(y_test, predictions))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Garbage"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "params = dict()\n",
    "params['C'] = (1e-6, 100.0, 'log-uniform')\n",
    "params['gamma'] = (1e-6, 100.0, 'log-uniform')\n",
    "params['degree'] = (1,5)\n",
    "params['kernel'] = ['linear', 'poly', 'rbf', 'sigmoid']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]# Create the random grid\n",
    "params = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All elements in list must be instances of <class 'skopt.space.space.Dimension'>, but found: ['n_estimators', 'max_features', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'bootstrap']",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-9-34af551b08a1>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     18\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     19\u001B[0m \u001B[0;31m# define the function used to evaluate a given configuration\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 20\u001B[0;31m \u001B[0;34m@\u001B[0m\u001B[0muse_named_args\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mparams\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     21\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mevaluate_model\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m**\u001B[0m\u001B[0mparams\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     22\u001B[0m         \u001B[0;31m# something\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/csapp/lib/python3.7/site-packages/skopt/utils.py\u001B[0m in \u001B[0;36mdecorator\u001B[0;34m(func)\u001B[0m\n\u001B[1;32m    748\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    749\u001B[0m         \u001B[0;31m# Ensure all dimensions are correctly typed.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 750\u001B[0;31m         \u001B[0mcheck_list_types\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdimensions\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mDimension\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    751\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    752\u001B[0m         \u001B[0;31m# Ensure all dimensions have names.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/csapp/lib/python3.7/site-packages/skopt/utils.py\u001B[0m in \u001B[0;36mcheck_list_types\u001B[0;34m(x, types)\u001B[0m\n\u001B[1;32m    636\u001B[0m         \u001B[0mmsg\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m\"All elements in list must be instances of {}, but found: {}\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    637\u001B[0m         \u001B[0mmsg\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmsg\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtypes\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0merr\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 638\u001B[0;31m         \u001B[0;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmsg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    639\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    640\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: All elements in list must be instances of <class 'skopt.space.space.Dimension'>, but found: ['n_estimators', 'max_features', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'bootstrap']"
     ]
    }
   ],
   "source": [
    "from numpy import mean\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from skopt.space import Integer\n",
    "from skopt.utils import use_named_args\n",
    "from skopt import gp_minimize\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# define the model\n",
    "model = SVC()\n",
    "# define the space of hyperparameters to search\n",
    "search_space = dict()\n",
    "search_space['C'] = (1e-6, 100.0, 'log-uniform')\n",
    "search_space['gamma'] = (1e-6, 100.0, 'log-uniform')\n",
    "search_space['degree'] = (1,5)\n",
    "search_space['kernel'] = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "\n",
    "# define the function used to evaluate a given configuration\n",
    "@use_named_args(params)\n",
    "def evaluate_model(**params):\n",
    "\t# something\n",
    "\tmodel.set_params(**params)\n",
    "\t# calculate 5-fold cross validation\n",
    "\tresult = cross_val_score(model, X, y, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "\t# calculate the mean of the scores\n",
    "\testimate = mean(result)\n",
    "\treturn 1.0 - estimate\n",
    "\n",
    "# perform optimization\n",
    "result = gp_minimize(evaluate_model, search_space)\n",
    "# summarizing finding:\n",
    "print('Best Accuracy: %.3f' % (1.0 - result.fun))\n",
    "print('Best Parameters: n_neighbors=%d, p=%d' % (result.x[0], result.x[1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}